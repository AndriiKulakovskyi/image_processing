{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "n2n_project.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOVw9urhyXdD",
        "outputId": "9fb97351-c4c1-4bde-f99b-cd7f797bda8a"
      },
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J0qw3KQz0JS"
      },
      "source": [
        "from math import log10\n",
        "from datetime import datetime\n",
        "from skimage.transform import resize\n",
        "import os, json, imageio, numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "from google.colab import drive\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSgIQYQM0Ey4"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, lr_scheduler\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as tvF\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwh93A8aOBjt"
      },
      "source": [
        "class BSDDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 root_dir,\n",
        "                 crop_size=64,\n",
        "                 noise_model='gaussian',\n",
        "                 noise_sigma=0.2,\n",
        "                 img_bitdepth=8,\n",
        "                 seed=None):\n",
        "        self.seed = seed\n",
        "        self.root_dir = root_dir\n",
        "        self.crop_size = crop_size\n",
        "        self.img_bitdepth = img_bitdepth\n",
        "        self.noise_model = noise_model\n",
        "        self.noise_sigma = noise_sigma\n",
        "        self.imgs = os.listdir(root_dir)\n",
        "\n",
        "        if self.seed:\n",
        "            np.random.seed(self.seed)\n",
        "      \n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "    \n",
        "    def _random_crop_to_size(self, img):\n",
        "        h, w, c = img.shape\n",
        "\n",
        "        if min(w, h) < self.crop_size:\n",
        "          img = resize(img, (self.crop_size, self.crop_size))\n",
        "\n",
        "        i = np.random.randint(0, h - self.crop_size)\n",
        "        j = np.random.randint(0, w - self.crop_size)\n",
        "\n",
        "        cropped_img = img[i:i+self.crop_size, j:j+self.crop_size, :]\n",
        "        return cropped_img\n",
        "    \n",
        "    def _add_gaussian_noise(self, image):\n",
        "        noisy_image = image + np.random.normal(0, self.noise_sigma, image.shape)\n",
        "        return np.clip(noisy_image, 0, 1)\n",
        "\n",
        "    def corrupt_image(self, image):\n",
        "        if self.noise_model == 'gaussian':\n",
        "            return self._add_gaussian_noise(image)\n",
        "        else:\n",
        "            raise ValueError('No such noise model.')\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Load image\n",
        "        img_path = os.path.join(self.root_dir, self.imgs[index])\n",
        "        image = imageio.imread(img_path) / (2**self.img_bitdepth - 1)\n",
        "\n",
        "        # Crop source image\n",
        "        if self.crop_size > 0:\n",
        "            image = self._random_crop_to_size(image)\n",
        "        \n",
        "        # Generate noisy images\n",
        "        image_noisy = self.corrupt_image(image)\n",
        "        image_target = self.corrupt_image(image)\n",
        "\n",
        "        # Transpose channels\n",
        "        image_target = np.array(image_target).transpose((2,0,1)) \n",
        "        image_noisy = np.array(image_noisy).transpose((2,0,1))\n",
        "\n",
        "        # Conver to tensor\n",
        "        image_target = torch.from_numpy(image_target).type(torch.DoubleTensor)\n",
        "        image_noisy = torch.from_numpy(image_noisy).type(torch.DoubleTensor)\n",
        "\n",
        "        return image_noisy, image_target"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h861lQyXWST"
      },
      "source": [
        "def conv_block(in_channels, out_channels):\n",
        "    return nn.Sequential(nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "                         nn.ReLU(inplace=True),\n",
        "                         nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "                         nn.ReLU(inplace=True))   \n",
        "\n",
        "class Denoiser(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.encode_1 = conv_block(3, 64)\n",
        "        self.encode_2 = conv_block(64, 128)\n",
        "        self.encode_3 = conv_block(128, 256)\n",
        "        self.encode_4 = conv_block(256, 512)        \n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2,\n",
        "                                    mode='bilinear',\n",
        "                                    align_corners=True)        \n",
        "        \n",
        "        self.decode_3 = conv_block(256 + 512, 256)\n",
        "        self.decode_2 = conv_block(128 + 256, 128)\n",
        "        self.decode_1 = conv_block(128 + 64, 64)\n",
        "        self.conv_last = nn.Conv2d(64, 3, 1)\n",
        "        \n",
        "    def forward(self, input_image):\n",
        "        conv1 = self.encode_1(input_image)\n",
        "        x = self.maxpool(conv1)\n",
        "\n",
        "        conv2 = self.encode_2(x)\n",
        "        x = self.maxpool(conv2)\n",
        "        \n",
        "        conv3 = self.encode_3(x)\n",
        "        x = self.maxpool(conv3)   \n",
        "        \n",
        "        x = self.encode_4(x)\n",
        "        \n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv3], dim=1)\n",
        "        \n",
        "        x = self.decode_3(x)\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv2], dim=1)       \n",
        "\n",
        "        x = self.decode_2(x)\n",
        "        x = self.upsample(x)        \n",
        "        x = torch.cat([x, conv1], dim=1)   \n",
        "        \n",
        "        x = self.decode_1(x)\n",
        "        \n",
        "        noise = self.conv_last(x)\n",
        "        \n",
        "        return input_image + noise"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuYo-zm6OB1Q"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XF3FmVGc-v1"
      },
      "source": [
        "***\n",
        "# Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6zCzt9Kc-EB"
      },
      "source": [
        "def clear_line():\n",
        "    \"\"\"Clears line from any characters.\"\"\"\n",
        "    print('\\r{}'.format(' ' * 80), end='\\r')\n",
        "\n",
        "\n",
        "def progress_bar(batch_idx, num_batches, report_interval, train_loss):\n",
        "    \"\"\"Neat progress bar to track training.\"\"\"\n",
        "\n",
        "    dec = int(np.ceil(np.log10(num_batches)))\n",
        "    bar_size = 21 + dec\n",
        "    progress = (batch_idx % report_interval) / report_interval\n",
        "    fill = int(progress * bar_size) + 1\n",
        "    print('\\rBatch {:>{dec}d} [{}{}] Train loss: {:>1.5f}'.format(batch_idx + 1, '=' * fill + '>', ' ' * (bar_size - fill), train_loss, dec=str(dec)), end='')\n",
        "\n",
        "\n",
        "def time_elapsed_since(start):\n",
        "    \"\"\"Computes elapsed time since start.\"\"\"\n",
        "\n",
        "    timedelta = datetime.now() - start\n",
        "    string = str(timedelta)[:-7]\n",
        "    ms = int(timedelta.total_seconds() * 1000)\n",
        "\n",
        "    return string, ms\n",
        "\n",
        "\n",
        "def show_on_epoch_end(epoch_time, valid_time, valid_loss, valid_psnr):\n",
        "    \"\"\"Formats validation error stats.\"\"\"\n",
        "\n",
        "    clear_line()\n",
        "    print('Train time: {} | Valid time: {} | Valid loss: {:>1.5f} | Avg PSNR: {:.2f} dB'.format(epoch_time, valid_time, valid_loss, valid_psnr))\n",
        "\n",
        "\n",
        "def show_on_report(batch_idx, num_batches, loss, elapsed):\n",
        "    \"\"\"Formats training stats.\"\"\"\n",
        "\n",
        "    clear_line()\n",
        "    dec = int(np.ceil(np.log10(num_batches)))\n",
        "    print('Batch {:>{dec}d} / {:d} | Avg loss: {:>1.5f} | Avg train time / batch: {:d} ms'.format(batch_idx + 1, num_batches, loss, int(elapsed), dec=dec))\n",
        "\n",
        "\n",
        "def plot_per_epoch(ckpt_dir, title, measurements, y_label):\n",
        "    \"\"\"Plots stats (train/valid loss, avg PSNR, etc.).\"\"\"\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(range(1, len(measurements) + 1), measurements)\n",
        "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel(y_label)\n",
        "    ax.set_title(title)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    fname = '{}.png'.format(title.replace(' ', '-').lower())\n",
        "    plot_fname = os.path.join(ckpt_dir, fname)\n",
        "    plt.savefig(plot_fname, dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "def psnr(input, target):\n",
        "    \"\"\"Computes peak signal-to-noise ratio.\"\"\"\n",
        "    \n",
        "    return 10 * torch.log10(1 / F.mse_loss(input, target))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVTFEDoKdLi1"
      },
      "source": [
        "class AvgMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value.\n",
        "    Useful for tracking averages such as elapsed times, minibatch losses, etc.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0.\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRdgcVglZuEe"
      },
      "source": [
        "***\n",
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyB_19bGZtqQ",
        "outputId": "0f62ee8b-064e-4278-a4f4-2e2e276b56e6"
      },
      "source": [
        "# Mount GDrive with dataset\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "# Path to BSDS500 image dataset\n",
        "root_train = '/content/drive/My Drive/Colab Notebooks/Data/BSDS500/train/'\n",
        "root_valid = '/content/drive/My Drive/Colab Notebooks/Data/BSDS500/val/'\n",
        "\n",
        "# Explore images\n",
        "print('Train images: ', len(os.listdir(root_train)))\n",
        "print('Valid images: ', len(os.listdir(root_valid)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Train images:  400\n",
            "Valid images:  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t6wVRO3aHV4"
      },
      "source": [
        "class Params:\n",
        "  def __init__(self):\n",
        "    self.train_dir = '/content/drive/My Drive/Colab Notebooks/Data/BSDS500/train/'\n",
        "    self.valid_dir = '/content/drive/My Drive/Colab Notebooks/Data/BSDS500/val/'\n",
        "    self.ckpt_save_path = '/content/drive/My Drive/Colab Notebooks'\n",
        "    self.nb_epochs = 10\n",
        "    self.batch_size = 4\n",
        "    self.learning_rate = 0.001\n",
        "    self.loss = 'l2'\n",
        "    self.noise_model = 'gaussian'\n",
        "    self.noise_sigma = 50\n",
        "    self.crop_size = 64\n",
        "    self.report_interval = 4\n",
        "    self.plot_stats = True\n",
        "    self.seed = 57\n",
        "    self.image_bitdepth = 8"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Y0nZqMSLKX"
      },
      "source": [
        "def get_loaders(params):\n",
        "    # Declare training / testing datsets\n",
        "    dataset_train = BSDDataset(params.train_dir,\n",
        "                               crop_size=params.crop_size,\n",
        "                               noise_model=params.noise_model,\n",
        "                               noise_sigma=params.noise_sigma)\n",
        "\n",
        "    dataset_valid = BSDDataset(params.valid_dir,\n",
        "                               crop_size=params.crop_size,\n",
        "                               noise_model=params.noise_model,\n",
        "                               noise_sigma=params.noise_sigma)\n",
        "\n",
        "    # Declare training / testing data loaders\n",
        "    train_loader = DataLoader(dataset_train, batch_size=params.batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(dataset_valid, batch_size=params.batch_size, shuffle=True)\n",
        "    return train_loader, valid_loader"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF41MeJuQqEb"
      },
      "source": [
        "def train_model(model, criterion, optim, train_loader, valid_loader, params):\n",
        "    model.train()\n",
        "    num_batches = len(train_loader)\n",
        "\n",
        "    # Dictionaries of tracked stats\n",
        "    stats = {'train_loss': [],\n",
        "             'valid_loss': [],\n",
        "             'valid_psnr': []}\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(params.nb_epochs):\n",
        "        print('Epoch {:d} / {:d}'.format(epoch + 1, params.nb_epochs))\n",
        "\n",
        "        # Init stat meters\n",
        "        loss_meter = AvgMeter()\n",
        "        time_meter = AvgMeter()\n",
        "        train_loss_meter = AvgMeter()\n",
        "\n",
        "        # Train on batches\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            batch_start = datetime.now()\n",
        "            progress_bar(batch_idx, num_batches, params.report_interval, loss_meter.val)\n",
        "\n",
        "            # Denoise image\n",
        "            results = model(inputs)\n",
        "            loss = criterion(results, targets)\n",
        "            loss_meter.update(loss.item())\n",
        "\n",
        "            # Zero gradients, perform a backward pass, and update the weights\n",
        "            optim.zero_grad()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            # Report/update statistics\n",
        "            time_meter.update(time_elapsed_since(batch_start)[1])\n",
        "            if (batch_idx + 1) % params.report_interval == 0 and batch_idx:\n",
        "                show_on_report(batch_idx, num_batches, loss_meter.avg, time_meter.avg)\n",
        "                train_loss_meter.update(loss_meter.avg)\n",
        "                loss_meter.reset()\n",
        "                time_meter.reset()\n",
        "\n",
        "        # Epoch end, save and reset tracker\n",
        "        # self._on_epoch_end(stats, train_loss_meter.avg, epoch, epoch_start, valid_loader)\n",
        "        train_loss_meter.reset()\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "\n",
        "        valid_start = datetime.now()\n",
        "        loss_meter = AvgMeter()\n",
        "        psnr_meter = AvgMeter()\n",
        "\n",
        "        for batch_idx, (inputs, targets) in enumerate(valid_loader):\n",
        "            # Denoise\n",
        "            results = model(inputs)\n",
        "\n",
        "            # Update loss\n",
        "            loss = self.loss(results, targets)\n",
        "            loss_meter.update(loss.item())\n",
        "\n",
        "            # Compute PSRN\n",
        "            images_in_batch = results.shape[0]\n",
        "            for i in range(images_in_batch):\n",
        "                results = results.cpu()\n",
        "                targets = targets.cpu()\n",
        "                psnr_meter.update(psnr(results[i], targets[i]).item())\n",
        "\n",
        "        valid_loss = loss_meter.avg\n",
        "        valid_time = time_elapsed_since(valid_start)[0]\n",
        "        psnr_avg = psnr_meter.avg\n",
        "        show_on_epoch_end(epoch_time, valid_time, valid_loss, valid_psnr)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dth5bYtCeI09"
      },
      "source": [
        "    def test(self, test_loader, show):\n",
        "        \"\"\"Evaluates denoiser on test set.\"\"\"\n",
        "\n",
        "        self.model.train(False)\n",
        "\n",
        "        source_imgs = []\n",
        "        denoised_imgs = []\n",
        "        clean_imgs = []\n",
        "\n",
        "        # Create directory for denoised images\n",
        "        denoised_dir = os.path.dirname(self.p.data)\n",
        "        save_path = os.path.join(denoised_dir, 'denoised')\n",
        "        if not os.path.isdir(save_path):\n",
        "            os.mkdir(save_path)\n",
        "\n",
        "        for batch_idx, (source, target) in enumerate(test_loader):\n",
        "            # Only do first <show> images\n",
        "            if show == 0 or batch_idx >= show:\n",
        "                break\n",
        "\n",
        "            source_imgs.append(source)\n",
        "            clean_imgs.append(target)\n",
        "\n",
        "            if self.use_cuda:\n",
        "                source = source.cuda()\n",
        "\n",
        "            # Denoise\n",
        "            denoised_img = self.model(source).detach()\n",
        "            denoised_imgs.append(denoised_img)\n",
        "\n",
        "        # Squeeze tensors\n",
        "        source_imgs = [t.squeeze(0) for t in source_imgs]\n",
        "        denoised_imgs = [t.squeeze(0) for t in denoised_imgs]\n",
        "        clean_imgs = [t.squeeze(0) for t in clean_imgs]\n",
        "\n",
        "        # Create montage and save images\n",
        "        print('Saving images and montages to: {}'.format(save_path))\n",
        "        for i in range(len(source_imgs)):\n",
        "            img_name = test_loader.dataset.imgs[i]\n",
        "            create_montage(img_name, self.p.noise_type, save_path, source_imgs[i], denoised_imgs[i], clean_imgs[i], show)\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3uCyxkedbUr"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nszZDpa_QqJM"
      },
      "source": [
        "params = Params()\n",
        "\n",
        "model = Denoiser().double()\n",
        "optim = Adam(model.parameters(), lr=params.learning_rate)\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVURH3SdYUl1"
      },
      "source": [
        "train_loader, valid_loader = get_loaders(params)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "_lHO0-biYUpG",
        "outputId": "1ce4b70e-3f4c-49a2-ebc5-e1e9a638e983"
      },
      "source": [
        "train_model(model, criterion, optim, train_loader, valid_loader, params)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 / 10\n",
            "Batch  1 [=>                      ] Train loss: 0.00000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-49beb540cf61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-aaa39d10d808>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optim, train_loader, valid_loader, params)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Zero gradients, perform a backward pass, and update the weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp3Wx4hqYUsd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE-vgAwbYUv_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nm0qiYMYUzw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNX-ZbG4QqNo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHgaRn0ycO1z",
        "outputId": "a767d00f-dfa5-4c8c-c843-83c48f524f27"
      },
      "source": [
        "params = Params()\n",
        "n2n = Noise2Noise(params, trainable=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Noise2Noise: Learning Image Restoration without Clean Data (Lethinen et al., 2018)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFwUXWTqCBxs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM-McPnNWSJJ",
        "outputId": "e4dca34a-6d86-4782-bb02-6f77c017f3ad"
      },
      "source": [
        "n2n.train(dloader_train, dloader_valid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training parameters: \n",
            "  Train dir = /content/drive/My Drive/Colab Notebooks/Data/BSDS500/train/\n",
            "  Valid dir = /content/drive/My Drive/Colab Notebooks/Data/BSDS500/val/\n",
            "  Ckpt save path = /content/drive/My Drive/Colab Notebooks\n",
            "  Nb epochs = 10\n",
            "  Batch size = 4\n",
            "  Learning rate = 0.001\n",
            "  Adam = [0.9, 0.99, 1e-08]\n",
            "  Loss = l2\n",
            "  Noise type = gaussian\n",
            "  Noise param = 50\n",
            "  Crop size = 64\n",
            "  Report interval = 4\n",
            "  Plot stats = True\n",
            "  Seed = 57\n",
            "  Image bitdepth = 8\n",
            "  Cuda = False\n",
            "  Clean targets = False\n",
            "  Ckpt overwrite = True\n",
            "\n",
            "EPOCH 1 / 10\n",
            "Batch  4 / 100 | Avg loss: 0.25787 | Avg train time / batch: 5309 ms\n",
            "Batch  8 / 100 | Avg loss: 0.08295 | Avg train time / batch: 5124 ms\n",
            "Batch 12 / 100 | Avg loss: 0.06237 | Avg train time / batch: 5118 ms\n",
            "Batch 16 / 100 | Avg loss: 0.04230 | Avg train time / batch: 5104 ms\n",
            "Batch 20 / 100 | Avg loss: 0.03580 | Avg train time / batch: 5075 ms\n",
            "Batch 24 / 100 | Avg loss: 0.02924 | Avg train time / batch: 5112 ms\n",
            "Batch 28 / 100 | Avg loss: 0.02631 | Avg train time / batch: 5097 ms\n",
            "Batch 32 / 100 | Avg loss: 0.02256 | Avg train time / batch: 5092 ms\n",
            "Batch 36 / 100 | Avg loss: 0.02155 | Avg train time / batch: 5099 ms\n",
            "Batch 40 / 100 | Avg loss: 0.02302 | Avg train time / batch: 5117 ms\n",
            "Batch 44 / 100 | Avg loss: 0.01942 | Avg train time / batch: 5141 ms\n",
            "Batch 48 / 100 | Avg loss: 0.01698 | Avg train time / batch: 5111 ms\n",
            "Batch 52 / 100 | Avg loss: 0.01731 | Avg train time / batch: 5083 ms\n",
            "Batch 56 / 100 | Avg loss: 0.02101 | Avg train time / batch: 5094 ms\n",
            "Batch 60 / 100 | Avg loss: 0.01714 | Avg train time / batch: 5110 ms\n",
            "Batch 64 / 100 | Avg loss: 0.01315 | Avg train time / batch: 5132 ms\n",
            "Batch 68 / 100 | Avg loss: 0.01809 | Avg train time / batch: 5116 ms\n",
            "Batch 72 / 100 | Avg loss: 0.01816 | Avg train time / batch: 5153 ms\n",
            "Batch 76 / 100 | Avg loss: 0.01759 | Avg train time / batch: 5146 ms\n",
            "Batch 80 / 100 | Avg loss: 0.01662 | Avg train time / batch: 5131 ms\n",
            "Batch 84 / 100 | Avg loss: 0.01674 | Avg train time / batch: 5099 ms\n",
            "Batch 88 / 100 | Avg loss: 0.01328 | Avg train time / batch: 5107 ms\n",
            "Batch 92 / 100 | Avg loss: 0.01274 | Avg train time / batch: 5112 ms\n",
            "Batch 96 / 100 | Avg loss: 0.01549 | Avg train time / batch: 5138 ms\n",
            "Batch 100 / 100 | Avg loss: 0.01723 | Avg train time / batch: 5143 ms\n",
            "Train time: 0:08:37 | Valid time: 0:01:11 | Valid loss: 0.01548 | Avg PSNR: 19.00 dB\n",
            "Saving checkpoint to: /content/drive/My Drive/Colab Notebooks/gaussian/n2n-gaussian.pt\n",
            "\n",
            "EPOCH 2 / 10\n",
            "Batch  4 / 100 | Avg loss: 0.01216 | Avg train time / batch: 5224 ms\n",
            "Batch  8 / 100 | Avg loss: 0.01512 | Avg train time / batch: 5187 ms\n",
            "Batch 12 / 100 | Avg loss: 0.01400 | Avg train time / batch: 5158 ms\n",
            "Batch 16 / 100 | Avg loss: 0.01519 | Avg train time / batch: 5155 ms\n",
            "Batch 20 / 100 | Avg loss: 0.01880 | Avg train time / batch: 5188 ms\n",
            "Batch 24 / 100 | Avg loss: 0.01144 | Avg train time / batch: 5231 ms\n",
            "Batch 28 / 100 | Avg loss: 0.01312 | Avg train time / batch: 5217 ms\n",
            "Batch 32 / 100 | Avg loss: 0.01020 | Avg train time / batch: 5229 ms\n",
            "Batch 36 / 100 | Avg loss: 0.01695 | Avg train time / batch: 5226 ms\n",
            "Batch 40 / 100 | Avg loss: 0.01427 | Avg train time / batch: 5189 ms\n",
            "Batch 44 / 100 | Avg loss: 0.01313 | Avg train time / batch: 5201 ms\n",
            "Batch 48 / 100 | Avg loss: 0.01596 | Avg train time / batch: 5134 ms\n",
            "Batch 52 / 100 | Avg loss: 0.01927 | Avg train time / batch: 5164 ms\n",
            "Batch 56 / 100 | Avg loss: 0.01648 | Avg train time / batch: 5163 ms\n",
            "Batch 60 / 100 | Avg loss: 0.01331 | Avg train time / batch: 5147 ms\n",
            "Batch 64 / 100 | Avg loss: 0.01637 | Avg train time / batch: 5146 ms\n",
            "Batch 68 / 100 | Avg loss: 0.01041 | Avg train time / batch: 5131 ms\n",
            "Batch 72 / 100 | Avg loss: 0.01304 | Avg train time / batch: 5165 ms\n",
            "Batch 76 / 100 | Avg loss: 0.01619 | Avg train time / batch: 5218 ms\n",
            "Batch 80 / 100 | Avg loss: 0.01620 | Avg train time / batch: 5215 ms\n",
            "Batch 84 / 100 | Avg loss: 0.01532 | Avg train time / batch: 5198 ms\n",
            "Batch 88 / 100 | Avg loss: 0.01614 | Avg train time / batch: 5159 ms\n",
            "Batch 92 / 100 | Avg loss: 0.01352 | Avg train time / batch: 5165 ms\n",
            "Batch 96 / 100 | Avg loss: 0.01544 | Avg train time / batch: 5171 ms\n",
            "Batch 100 / 100 | Avg loss: 0.01693 | Avg train time / batch: 5165 ms\n",
            "Train time: 0:08:43 | Valid time: 0:00:55 | Valid loss: 0.01384 | Avg PSNR: 19.85 dB\n",
            "Saving checkpoint to: /content/drive/My Drive/Colab Notebooks/gaussian/n2n-gaussian.pt\n",
            "\n",
            "EPOCH 3 / 10\n",
            "Batch  4 / 100 | Avg loss: 0.01635 | Avg train time / batch: 5210 ms\n",
            "Batch  8 / 100 | Avg loss: 0.01159 | Avg train time / batch: 5235 ms\n",
            "Batch 12 / 100 | Avg loss: 0.01205 | Avg train time / batch: 5233 ms\n",
            "Batch 16 / 100 | Avg loss: 0.01156 | Avg train time / batch: 5235 ms\n",
            "Batch 20 / 100 | Avg loss: 0.01314 | Avg train time / batch: 5199 ms\n",
            "Batch 24 / 100 | Avg loss: 0.01773 | Avg train time / batch: 5213 ms\n",
            "Batch 28 / 100 | Avg loss: 0.01088 | Avg train time / batch: 5196 ms\n",
            "Batch 32 / 100 | Avg loss: 0.01670 | Avg train time / batch: 5166 ms\n",
            "Batch 36 / 100 | Avg loss: 0.01477 | Avg train time / batch: 5191 ms\n",
            "Batch 40 / 100 | Avg loss: 0.01638 | Avg train time / batch: 5174 ms\n",
            "Batch 44 / 100 | Avg loss: 0.01336 | Avg train time / batch: 5167 ms\n",
            "Batch 48 / 100 | Avg loss: 0.01134 | Avg train time / batch: 5180 ms\n",
            "Batch 52 / 100 | Avg loss: 0.01600 | Avg train time / batch: 5196 ms\n",
            "Batch 56 / 100 | Avg loss: 0.01303 | Avg train time / batch: 5207 ms\n",
            "Batch 60 / 100 | Avg loss: 0.01251 | Avg train time / batch: 5248 ms\n",
            "Batch 64 / 100 | Avg loss: 0.01591 | Avg train time / batch: 5232 ms\n",
            "Batch 68 / 100 | Avg loss: 0.01258 | Avg train time / batch: 5207 ms\n",
            "Batch 72 / 100 | Avg loss: 0.01866 | Avg train time / batch: 5238 ms\n",
            "Batch 76 / 100 | Avg loss: 0.01265 | Avg train time / batch: 5218 ms\n",
            "Batch 80 / 100 | Avg loss: 0.01400 | Avg train time / batch: 5187 ms\n",
            "Batch 84 / 100 | Avg loss: 0.01893 | Avg train time / batch: 5244 ms\n",
            "Batch 88 / 100 | Avg loss: 0.01466 | Avg train time / batch: 5217 ms\n",
            "Batch 92 / 100 | Avg loss: 0.01338 | Avg train time / batch: 5196 ms\n",
            "Batch 96 / 100 | Avg loss: 0.01185 | Avg train time / batch: 5252 ms\n",
            "Batch 100 / 100 | Avg loss: 0.01503 | Avg train time / batch: 5191 ms\n",
            "Train time: 0:08:46 | Valid time: 0:00:56 | Valid loss: 0.01314 | Avg PSNR: 20.21 dB\n",
            "Saving checkpoint to: /content/drive/My Drive/Colab Notebooks/gaussian/n2n-gaussian.pt\n",
            "\n",
            "EPOCH 4 / 10\n",
            "Batch  4 / 100 | Avg loss: 0.01458 | Avg train time / batch: 5098 ms\n",
            "Batch  8 / 100 | Avg loss: 0.01148 | Avg train time / batch: 5119 ms\n",
            "Batch 12 / 100 | Avg loss: 0.01432 | Avg train time / batch: 5079 ms\n",
            "Batch 16 / 100 | Avg loss: 0.01670 | Avg train time / batch: 5125 ms\n",
            "Batch 20 / 100 | Avg loss: 0.01482 | Avg train time / batch: 5068 ms\n",
            "Batch 24 / 100 | Avg loss: 0.00986 | Avg train time / batch: 5095 ms\n",
            "Batch 28 / 100 | Avg loss: 0.01465 | Avg train time / batch: 5085 ms\n",
            "Batch 32 / 100 | Avg loss: 0.01415 | Avg train time / batch: 5072 ms\n",
            "Batch 36 / 100 | Avg loss: 0.01501 | Avg train time / batch: 5087 ms\n",
            "Batch 40 / 100 | Avg loss: 0.01236 | Avg train time / batch: 5114 ms\n",
            "Batch 44 / 100 | Avg loss: 0.01804 | Avg train time / batch: 5143 ms\n",
            "Batch 48 / 100 | Avg loss: 0.01848 | Avg train time / batch: 5141 ms\n",
            "Batch 52 / 100 | Avg loss: 0.01049 | Avg train time / batch: 5139 ms\n",
            "Batch 56 / 100 | Avg loss: 0.01092 | Avg train time / batch: 5154 ms\n",
            "Batch 60 / 100 | Avg loss: 0.01558 | Avg train time / batch: 5133 ms\n",
            "Batch 64 / 100 | Avg loss: 0.01045 | Avg train time / batch: 5109 ms\n",
            "Batch 68 / 100 | Avg loss: 0.01297 | Avg train time / batch: 5126 ms\n",
            "Batch 72 / 100 | Avg loss: 0.01239 | Avg train time / batch: 5132 ms\n",
            "Batch 76 / 100 | Avg loss: 0.00837 | Avg train time / batch: 5119 ms\n",
            "Batch 80 / 100 | Avg loss: 0.01095 | Avg train time / batch: 5116 ms\n",
            "Batch 84 / 100 | Avg loss: 0.01230 | Avg train time / batch: 5110 ms\n",
            "Batch 88 / 100 | Avg loss: 0.01180 | Avg train time / batch: 5115 ms\n",
            "Batch 92 / 100 | Avg loss: 0.01887 | Avg train time / batch: 5160 ms\n",
            "Batch 96 / 100 | Avg loss: 0.01388 | Avg train time / batch: 5178 ms\n",
            "Batch 100 / 100 | Avg loss: 0.01648 | Avg train time / batch: 5139 ms\n",
            "Train time: 0:08:37 | Valid time: 0:00:56 | Valid loss: 0.01361 | Avg PSNR: 20.05 dB\n",
            "Saving checkpoint to: /content/drive/My Drive/Colab Notebooks/gaussian/n2n-gaussian.pt\n",
            "\n",
            "EPOCH 5 / 10\n",
            "Batch  4 / 100 | Avg loss: 0.01597 | Avg train time / batch: 5163 ms\n",
            "Batch  8 / 100 | Avg loss: 0.00901 | Avg train time / batch: 5129 ms\n",
            "Batch 12 / 100 | Avg loss: 0.01000 | Avg train time / batch: 5170 ms\n",
            "Batch 16 / 100 | Avg loss: 0.01688 | Avg train time / batch: 5186 ms\n",
            "Batch 20 / 100 | Avg loss: 0.01518 | Avg train time / batch: 5224 ms\n",
            "Batch 24 / 100 | Avg loss: 0.01090 | Avg train time / batch: 5236 ms\n",
            "Batch 28 / 100 | Avg loss: 0.01384 | Avg train time / batch: 5215 ms\n",
            "Batch 32 / 100 | Avg loss: 0.01175 | Avg train time / batch: 5214 ms\n",
            "Batch 36 / 100 | Avg loss: 0.01303 | Avg train time / batch: 5223 ms\n",
            "Batch 40 / 100 | Avg loss: 0.01188 | Avg train time / batch: 5205 ms\n",
            "Batch 44 / 100 | Avg loss: 0.00872 | Avg train time / batch: 5191 ms\n",
            "Batch 48 / 100 | Avg loss: 0.01047 | Avg train time / batch: 5204 ms\n",
            "Batch 52 / 100 | Avg loss: 0.01394 | Avg train time / batch: 5197 ms\n",
            "Batch 56 / 100 | Avg loss: 0.01193 | Avg train time / batch: 5182 ms\n",
            "Batch 60 / 100 | Avg loss: 0.01177 | Avg train time / batch: 5172 ms\n",
            "Batch 64 / 100 | Avg loss: 0.01598 | Avg train time / batch: 5194 ms\n",
            "Batch 68 / 100 | Avg loss: 0.01220 | Avg train time / batch: 5170 ms\n",
            "Batch 72 / 100 | Avg loss: 0.01270 | Avg train time / batch: 5183 ms\n",
            "Batch 76 / 100 | Avg loss: 0.01445 | Avg train time / batch: 5153 ms\n",
            "Batch 80 / 100 | Avg loss: 0.01517 | Avg train time / batch: 5203 ms\n",
            "Batch 84 / 100 | Avg loss: 0.01580 | Avg train time / batch: 5153 ms\n",
            "Batch 88 / 100 | Avg loss: 0.00978 | Avg train time / batch: 5186 ms\n",
            "Batch 92 / 100 | Avg loss: 0.00998 | Avg train time / batch: 5144 ms\n",
            "Batch 96 / 100 | Avg loss: 0.01148 | Avg train time / batch: 5151 ms\n",
            "Batch 100 / 100 | Avg loss: 0.01326 | Avg train time / batch: 5151 ms\n",
            "Train time: 0:08:43 | Valid time: 0:00:55 | Valid loss: 0.01559 | Avg PSNR: 19.48 dB\n",
            "Saving checkpoint to: /content/drive/My Drive/Colab Notebooks/gaussian/n2n-gaussian.pt\n",
            "\n",
            "EPOCH 6 / 10\n",
            "Batch  4 / 100 | Avg loss: 0.01414 | Avg train time / batch: 5189 ms\n",
            "Batch  8 / 100 | Avg loss: 0.01851 | Avg train time / batch: 5188 ms\n",
            "Batch 12 / 100 | Avg loss: 0.01810 | Avg train time / batch: 5175 ms\n",
            "Batch 16 / 100 | Avg loss: 0.01302 | Avg train time / batch: 5192 ms\n",
            "Batch 20 / 100 | Avg loss: 0.01409 | Avg train time / batch: 5162 ms\n",
            "Batch 24 / 100 | Avg loss: 0.01030 | Avg train time / batch: 5181 ms\n",
            "Batch 28 / 100 | Avg loss: 0.01417 | Avg train time / batch: 5201 ms\n",
            "Batch 32 / 100 | Avg loss: 0.01283 | Avg train time / batch: 5186 ms\n",
            "Batch 36 / 100 | Avg loss: 0.01550 | Avg train time / batch: 5158 ms\n",
            "Batch 40 / 100 | Avg loss: 0.01517 | Avg train time / batch: 5174 ms\n",
            "Batch 44 / 100 | Avg loss: 0.01185 | Avg train time / batch: 5191 ms\n",
            "Batch 48 / 100 | Avg loss: 0.01124 | Avg train time / batch: 5198 ms\n",
            "Batch 52 / 100 | Avg loss: 0.01081 | Avg train time / batch: 5178 ms\n",
            "Batch 56 / 100 | Avg loss: 0.01548 | Avg train time / batch: 5201 ms\n",
            "Batch 60 / 100 | Avg loss: 0.01389 | Avg train time / batch: 5194 ms\n",
            "Batch 64 [==================>     ] Train loss: 0.01608"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDnw8M2xWSaK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKR_Mkr7WScr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}